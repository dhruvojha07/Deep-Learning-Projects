{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ce7b223-1756-412c-851e-47f4057b5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pathlib\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,LayerNormalization,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input,MultiHeadAttention,Embedding,TextVectorization)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5bf2b1-a380-4310-9a04-f9e778572d33",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eac00c0-c4ed-4d29-ae5b-1365458f2d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:03:46.556890: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-29 14:03:46.733640: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-29 14:03:46.733731: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-29 14:03:46.738159: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-29 14:03:46.738250: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-29 14:03:46.738307: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-29 14:03:47.030522: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-29 14:03:47.030619: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-29 14:03:47.030631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-29 14:03:47.030726: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-29 14:03:47.030760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "text_dataset=tf.data.TextLineDataset(\"/mnt/c/Users/Lenovo/Desktop/DS/Datasets/France-English/fra.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b0925e-fefb-486c-bd4e-aaed98fec3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=20000\n",
    "ENGLISH_SEQUENCE_LENGTH=64\n",
    "FRENCH_SEQUENCE_LENGTH=64\n",
    "EMBEDDING_DIM=300\n",
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afed2da2-eee0-485c-bf55-91b2c309f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vectorize_layer=TextVectorization(\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b9c344-89fa-43a7-8d49-89bbfebf44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_vectorize_layer=TextVectorization(\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4237e7e-c6c6-4782-9c20-49055d35c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selector(input_text):\n",
    "  split_text=tf.strings.split(input_text,'\\t')\n",
    "  return {'input_1':split_text[0:1],'input_2':'starttoken '+split_text[1:2]},split_text[1:2]+' endtoken'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab797b1b-8eba-4533-b16c-4295f51a7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset=text_dataset.map(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f1b877-f954-41fe-baa3-24899177c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separator(input_text):\n",
    "  split_text=tf.strings.split(input_text,'\\t')\n",
    "  return split_text[0:1],'starttoken '+split_text[1:2]+' endtoken'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5bcc23-a0e5-4178-8f31-9123be1a0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_dataset=text_dataset.map(separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e925a3e7-90ec-477b-b532-860466b7b041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:11:07.205868: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13428602457202197591\n",
      "2024-07-29 14:11:07.205953: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5804838831961897312\n",
      "2024-07-29 14:11:07.206000: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4448343679240827522\n"
     ]
    }
   ],
   "source": [
    "english_training_data=init_dataset.map(lambda x,y:x) # input x,y and output x\n",
    "english_vectorize_layer.adapt(english_training_data) # adapt the vectorize_layer to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c8e0594-445c-4806-8f7e-624f76b0c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:18:38.041216: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13428602457202197591\n",
      "2024-07-29 14:18:38.041288: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5804838831961897312\n",
      "2024-07-29 14:18:38.041334: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4448343679240827522\n"
     ]
    }
   ],
   "source": [
    "french_training_data=init_dataset.map(lambda x,y:y) # input x,y,z and output y\n",
    "french_vectorize_layer.adapt(french_training_data) # adapt the vectorize_layer to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2580fa1a-b663-474c-89b5-764c3b71e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(inputs,output):\n",
    "  return {'input_1':english_vectorize_layer(inputs['input_1']),\n",
    "          'input_2':french_vectorize_layer(inputs['input_2'])},french_vectorize_layer(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9f090a3-56c1-4a2a-93b6-500f28d3d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=split_dataset.map(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2495b054-3850-4f72-b463-181b3387b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e78eab06-e750-4373-81c2-32ee8ee0dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BATCHES=int(200000/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51588e9c-c744-4500-8e00-3cb5bdbd4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n",
    "val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47481526-45d1-40dc-adf4-00edcfb1c74f",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d8fea-b08b-4e8c-936d-cd5d96c573cc",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02013aea-6f26-4f99-98c4-31b991993ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(model_size,SEQUENCE_LENGTH):\n",
    "  output=[]\n",
    "  for pos in range(SEQUENCE_LENGTH):\n",
    "    PE=np.zeros((model_size))\n",
    "    for i in range(model_size):\n",
    "      if i%2==0:\n",
    "        PE[i]=np.sin(pos/(10000**(i/model_size)))\n",
    "      else:\n",
    "        PE[i]=np.cos(pos/(10000**((i-1)/model_size)))\n",
    "    output.append(tf.expand_dims(PE,axis=0))\n",
    "  out=tf.concat(output,axis=0)\n",
    "  out=tf.expand_dims(out,axis=0)\n",
    "  return tf.cast(out,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c53ee86-e4a7-4048-a9a9-0be47ec9fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 256)\n"
     ]
    }
   ],
   "source": [
    "print(positional_encoding(256,64).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b8df3f9-3648-4055-ae96-53bb7180cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(Layer):\n",
    "  def __init__(self, sequence_length, vocab_size, embed_dim,):\n",
    "    super(Embeddings, self).__init__()\n",
    "    self.token_embeddings=Embedding(\n",
    "        input_dim=vocab_size, output_dim=embed_dim)\n",
    "    self.sequence_length = sequence_length\n",
    "    self.vocab_size = vocab_size\n",
    "    self.embed_dim = embed_dim\n",
    "\n",
    "  def call(self, inputs):\n",
    "    embedded_tokens = self.token_embeddings(inputs)\n",
    "    embedded_positions=positional_encoding(\n",
    "        self.embed_dim,self.sequence_length)\n",
    "    return embedded_tokens + embedded_positions\n",
    "\n",
    "  def compute_mask(self, inputs, mask=None):\n",
    "    return tf.math.not_equal(inputs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2b4cf15-1738-4a4a-8d09-858c38db0bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "test_input=tf.constant([[2,4,7,21,3,5,0,0]])\n",
    "emb=Embeddings(8,20000,512)\n",
    "emb_out=emb(test_input)\n",
    "print(emb_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f33d925-29da-4a03-9433-9a17680ca542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ True  True  True  True  True  True False False]], shape=(1, 8), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[1 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 0 0]], shape=(8, 8), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "mask = emb.compute_mask(test_input)\n",
    "print(mask)\n",
    "\n",
    "\n",
    "padding_mask = tf.cast(\n",
    "    tf.repeat(mask,repeats=tf.shape(mask)[1],axis=0),\n",
    "    dtype=tf.int32)\n",
    "print(padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14315c23-6113-4df3-8620-cb748d2b8f97",
   "metadata": {},
   "source": [
    "### Custom MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec73cf3-fe47-4e2f-b296-66e4015d9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSelfAttention(Layer):\n",
    "  def __init__(self,model_size):\n",
    "    super(CustomSelfAttention,self).__init__()\n",
    "    self.model_size=model_size\n",
    "  def call(self,query,key,value,masking):\n",
    "    # compute scores\n",
    "    score=tf.matmul(query,key,transpose_b=True)\n",
    "    # scaling\n",
    "    score/=tf.math.sqrt(tf.cast(self.model_size,tf.float32))\n",
    "    # masking\n",
    "    masking=tf.cast(masking,dtype=tf.float32)\n",
    "    score+=(1.-masking)*-1e10\n",
    "    # attention_weights\n",
    "    attention=tf.nn.softmax(score,axis=-1)*masking\n",
    "    # output\n",
    "    head=tf.matmul(attention,value)\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e47b8b20-7c43-4e82-adb9-0af1db26685e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:18:38.735577: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8, 256), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention=CustomSelfAttention(256)\n",
    "attention(tf.ones([1,8,256]),tf.ones([1,8,256]),tf.ones([1,8,256]),padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "515aad08-bbec-41b9-9ba2-bcf4bf2e9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMultiHeadAttention(Layer):\n",
    "  def __init__(self,num_heads,key_dim):\n",
    "    super(CustomMultiHeadAttention,self).__init__()\n",
    "\n",
    "    self.num_heads=num_heads\n",
    "    self.dense_q=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n",
    "    self.dense_k=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n",
    "    self.dense_v=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n",
    "    self.dense_o=Dense(key_dim)\n",
    "    self.self_attention=CustomSelfAttention(key_dim)\n",
    "\n",
    "  def call(self,query,key,value,attention_mask):\n",
    "    heads=[]\n",
    "\n",
    "    for i in range(self.num_heads):\n",
    "      self.dense_q[i](query)\n",
    "      head=self.self_attention(self.dense_q[i](query),self.dense_k[i](key),\n",
    "                              self.dense_v[i](value),attention_mask)\n",
    "      heads.append(head)\n",
    "    tf.convert_to_tensor(heads)\n",
    "    heads=tf.concat(heads,axis=2)\n",
    "    heads=self.dense_o(heads)\n",
    "    return heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c3c6180-3b16-4f9e-9a52-2bb5cace6532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8, 256), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention=CustomSelfAttention(256)\n",
    "attention(tf.ones([1,8,256]),tf.ones([1,8,256]),tf.ones([1,8,256]),padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a7997-cf38-4928-98b8-e10504654055",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70ecd384-724e-44be-985c-0bd0bfe86eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads,):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = CustomMultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim,\n",
    "        )\n",
    "        self.dense_proj=tf.keras.Sequential(\n",
    "            [Dense(dense_dim, activation=\"relu\"),\n",
    "             Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = LayerNormalization()\n",
    "        self.layernorm_2 = LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "\n",
    "      if mask is not None:\n",
    "        mask = tf.cast(\n",
    "            mask[:,tf.newaxis, :], dtype=\"int32\")\n",
    "        T = tf.shape(mask)[2]\n",
    "        padding_mask = tf.repeat(mask,T,axis=1)\n",
    "      attention_output = self.attention(\n",
    "          query=inputs, key=inputs,value=inputs,\n",
    "          attention_mask=padding_mask\n",
    "      )\n",
    "\n",
    "      proj_input = self.layernorm_1(inputs + attention_output)\n",
    "      proj_output = self.dense_proj(proj_input)\n",
    "      return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f6c07ad-a037-4b7e-8707-cca639ff7fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs = TransformerEncoder(512,2048,8)(emb_out)\n",
    "print(encoder_outputs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c5ba6-6c48-4479-bb61-91b81f276d62",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4caafc7-bf96-43ae-a4a0-a5eef377bcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(Layer):\n",
    "  def __init__(self, embed_dim, latent_dim, num_heads,):\n",
    "    super(TransformerDecoder, self).__init__()\n",
    "    self.embed_dim = embed_dim\n",
    "    self.latent_dim = latent_dim\n",
    "    self.num_heads = num_heads\n",
    "    self.attention_1=MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=embed_dim\n",
    "    )\n",
    "    self.attention_2=MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=embed_dim\n",
    "    )\n",
    "    self.dense_proj = tf.keras.Sequential(\n",
    "        [Dense(latent_dim, activation=\"relu\"),Dense(embed_dim),]\n",
    "    )\n",
    "    self.layernorm_1=LayerNormalization()\n",
    "    self.layernorm_2=LayerNormalization()\n",
    "    self.layernorm_3=LayerNormalization()\n",
    "    self.supports_masking = True\n",
    "  def call(self, inputs, encoder_outputs, enc_mask, mask=None):\n",
    "\n",
    "\n",
    "    if mask is not None:\n",
    "      causal_mask=tf.linalg.band_part(\n",
    "        tf.ones([tf.shape(inputs)[0],\n",
    "                 tf.shape(inputs)[1],\n",
    "                 tf.shape(inputs)[1]],dtype=tf.int32),-1,0)\n",
    "      mask = tf.cast(\n",
    "          mask[:,tf.newaxis, :], dtype=\"int32\")\n",
    "      enc_mask = tf.cast(\n",
    "          enc_mask[:,tf.newaxis, :], dtype=\"int32\")\n",
    "      T = tf.shape(mask)[2]\n",
    "      padding_mask = tf.repeat(mask,T,axis=1)\n",
    "      cross_attn_mask = tf.repeat(enc_mask,T,axis=1)\n",
    "      combined_mask=tf.minimum(padding_mask,causal_mask)\n",
    "\n",
    "    attention_output_1 = self.attention_1(\n",
    "        query=inputs,key=inputs,value=inputs,\n",
    "        attention_mask=combined_mask,\n",
    "\n",
    "    )\n",
    "\n",
    "    out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "    attention_output_2= self.attention_2(\n",
    "        query=out_1,key=encoder_outputs,value=encoder_outputs,\n",
    "        attention_mask=cross_attn_mask,\n",
    "\n",
    "    )\n",
    "    out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "    proj_output = self.dense_proj(out_2)\n",
    "    return self.layernorm_3(out_2 + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9116feaa-bd7b-4889-b43c-f1b6bbf6f224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "enc_mask=mask\n",
    "decoder_outputs = TransformerDecoder(512,2048,4)(emb_out,encoder_outputs,enc_mask)\n",
    "print(decoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ecd116-ed0e-4dd6-a2d5-118963a020dd",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e87a264-0b2d-43ff-aec1-0aa6a279c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=512\n",
    "D_FF=2048\n",
    "NUM_HEADS=8\n",
    "NUM_LAYERS=1\n",
    "NUM_EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1af82f06-46c2-48e9-97db-da18014d24af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embeddings_7 (Embeddings)   (None, 64, 512)              1024000   ['input_1[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embeddings_8 (Embeddings)   (None, 64, 512)              1024000   ['input_2[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " transformer_encoder_6 (Tra  (None, 64, 512)              3152384   ['embeddings_7[0][0]']        \n",
      " nsformerEncoder)                                                                                 \n",
      "                                                                                                  \n",
      " tf.math.not_equal_3 (TFOpL  (None, None)                 0         ['input_1[0][0]']             \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " transformer_decoder_9 (Tra  (None, 64, 512)              1890560   ['embeddings_8[0][0]',        \n",
      " nsformerDecoder)                                         0          'transformer_encoder_6[0][0]'\n",
      "                                                                    , 'tf.math.not_equal_3[0][0]']\n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 64, 512)              0         ['transformer_decoder_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_210 (Dense)           (None, 64, 20000)            1026000   ['dropout_11[0][0]']          \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52797984 (201.41 MB)\n",
      "Trainable params: 52797984 (201.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_1\")\n",
    "emb = Embeddings(ENGLISH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)\n",
    "x = emb(encoder_inputs)\n",
    "enc_mask = emb.compute_mask(encoder_inputs)\n",
    "\n",
    "for _ in range(NUM_LAYERS):\n",
    "  x=TransformerEncoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x)\n",
    "encoder_outputs=x\n",
    "\n",
    "decoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_2\")\n",
    "\n",
    "x = Embeddings(FRENCH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(decoder_inputs)\n",
    "for i in range(NUM_LAYERS):\n",
    "  x=TransformerDecoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x, encoder_outputs,enc_mask)\n",
    "x=tf.keras.layers.Dropout(0.5)(x)\n",
    "decoder_outputs=Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "\n",
    "transformer = tf.keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")\n",
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26bd29-ddb6-4a0e-9133-864c8612bb81",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b986b0a-e3b1-4395-a554-e7d599a78c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scheduler(LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps):\n",
    "    super(Scheduler, self).__init__()\n",
    "    self.d_model = tf.cast(d_model, tf.float64)\n",
    "    self.warmup_steps = tf.cast(warmup_steps, dtype=tf.float64)\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float64)\n",
    "    return (self.d_model**(-0.5))*tf.math.minimum(step**(-0.5), step * (self.warmup_steps ** -1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7334841a-9f37-43c5-9c20-8a8c5234c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARM_UP_STEPS = 4000\n",
    "lr_scheduled = Scheduler(EMBEDDING_DIM, WARM_UP_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b430a56-9ca2-4e4c-962c-45375fd80f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = Adam(lr_scheduled, beta_1=0.9, beta_2=0.98, epsilon=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c0c0dfb-1bc5-4ec8-9ee5-bf680ee25764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   2812/Unknown - 796s 275ms/step - loss: 4.6148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:58:56.510383: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13267868364043608559\n",
      "2024-07-29 14:58:56.510544: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 16307297600030887803\n",
      "2024-07-29 14:58:56.510569: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13137102093968465928\n",
      "2024-07-29 14:58:56.510576: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 18391323184288776522\n",
      "2024-07-29 14:58:56.510586: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16107269560509501712\n",
      "2024-07-29 14:58:56.510591: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 15143885862197083568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2812/2812 [==============================] - 947s 329ms/step - loss: 4.6148 - val_loss: 4.0317\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:01:27.124604: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4110900089119033996\n",
      "2024-07-29 15:01:27.124702: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 17932275505488407586\n",
      "2024-07-29 15:01:27.124753: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 2769110157957001179\n",
      "2024-07-29 15:01:27.124777: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 1539682801848899549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2812/2812 [==============================] - 914s 325ms/step - loss: 2.8456 - val_loss: 3.2953\n",
      "Epoch 3/3\n",
      "2812/2812 [==============================] - 895s 318ms/step - loss: 2.2655 - val_loss: 3.0590\n"
     ]
    }
   ],
   "source": [
    "history=transformer.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    verbose = 1,\n",
    "    epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b96c7-d53d-475a-a18d-eef9ef381c6a",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40e35936-e6e3-497e-8564-5e20211f77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word={x:y for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
    "                                   french_vectorize_layer.get_vocabulary())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "13b50d0c-5179-4979-abe0-2d88137973eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(english_sentence):\n",
    "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
    "  shifted_target='starttoken'\n",
    "\n",
    "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
    "    tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
    "    output=transformer.predict([tokenized_english_sentence,tokenized_shifted_target])\n",
    "    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n",
    "    current_word=index_to_word[french_word_index]\n",
    "    if current_word=='endtoken':\n",
    "      break\n",
    "    shifted_target+=' '+current_word\n",
    "  return shifted_target[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6344222c-7721-4986-9442-3d5172eef2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'quelle est ton nom de ton nom'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"what is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b6847-0ad7-4cb8-815d-61ca0e277e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
