{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e21a17-9d27-45ee-bce4-980090688532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 19:04:02.521135: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-01 19:04:02.521206: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-01 19:04:02.531105: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-01 19:04:02.600793: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-01 19:04:03.970284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Dense,Flatten,InputLayer,BatchNormalization,Dropout,Input,LayerNormalization\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from datasets import load_dataset\n",
    "from transformers import (DataCollatorWithPadding,create_optimizer,DebertaTokenizerFast, DebertaV2ForQuestionAnswering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adbdb438-1c48-416b-91f2-52299836f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "MAX_LENGTH=512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d566d-3ee5-46d4-9b40-d5f70bfd199c",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19ebd78-eaa7-4cb8-a383-f7a528f55d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_dataset(\"squad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941721b5-abed-45a7-aa14-ba40e91ecf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"microsoft/deberta-base\"\n",
    "tokenizer=DebertaTokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69383272-ea42-425b-a306-ecc6dbc41aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_examples = tokenizer(\n",
    "    dataset['train'][0]['question'],\n",
    "    dataset['train'][0][\"context\"],\n",
    "    truncation=\"only_second\",\n",
    "    max_length=MAX_LENGTH,\n",
    "    stride=64,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=\"max_length\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c841b028-c673-4f2e-ba21-b8d224441940",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "tokenized_examples[\"start_positions\"] = []#[152,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "tokenized_examples[\"end_positions\"] = []#[172,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8775c07d-b1f6-49f8-9b46-9beb892bbeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, offsets in enumerate(offset_mapping):\n",
    "  if len(dataset['train'][0]['answers']['answer_start'])==0:\n",
    "    tokenized_examples[\"start_positions\"].append(0)\n",
    "    tokenized_examples[\"end_positions\"].append(0)\n",
    "  else:\n",
    "      \n",
    "    start_char=dataset['train'][0]['answers']['answer_start'][0]\n",
    "    end_char=start_char+len(dataset['train'][0]['answers']['text'][0])\n",
    "    found=0\n",
    "    start_token_position=0\n",
    "    end_token_position=0\n",
    "    \n",
    "    for j,offset in enumerate(offsets):\n",
    "      if offset[0]<=start_char and offset[1]>=start_char and found==0:\n",
    "        start_token_position=j\n",
    "        end_token_position=MAX_LENGTH\n",
    "        \n",
    "        found=1\n",
    "      if offset[1]>=end_char and found==1:\n",
    "        end_token_position=j\n",
    "        break\n",
    "    tokenized_examples[\"start_positions\"].append(start_token_position)\n",
    "    tokenized_examples[\"end_positions\"].append(end_token_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063b0fb7-da7d-47f8-80c5-53591b0f01f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134]\n",
      "[141]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_examples['start_positions'])\n",
    "print(tokenized_examples['end_positions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d799af16-163a-417d-a128-a9b3d47678bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "  \n",
    "  questions = [q.lstrip() for q in dataset[\"question\"]]\n",
    "  paragraphs = [p.lstrip() for p in dataset[\"context\"]]\n",
    "  \n",
    "  tokenized_examples = tokenizer(\n",
    "    questions,\n",
    "    paragraphs,\n",
    "    truncation=\"only_second\",\n",
    "    max_length=MAX_LENGTH,\n",
    "    stride=64,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=\"max_length\",\n",
    "  )\n",
    "  sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "  offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "  tokenized_examples[\"start_positions\"] = []#[152,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "  tokenized_examples[\"end_positions\"] = []#[172,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "  for i, offsets in enumerate(offset_mapping):\n",
    "    sample_index = sample_mapping[i]\n",
    "\n",
    "    start_char=dataset[\"answers\"][sample_index]['answer_start'][0]\n",
    "    end_char=start_char+len(dataset[\"answers\"][sample_index]['text'][0])\n",
    "    found=0\n",
    "    start_token_position=0\n",
    "    end_token_position=0\n",
    "    \n",
    "    for j,offset in enumerate(offsets):\n",
    "      if offset[0]<=start_char and offset[1]>=start_char and found==0:\n",
    "        start_token_position=j\n",
    "        end_token_position=MAX_LENGTH\n",
    "        found=1\n",
    "      if offset[1]>=end_char and found==1:\n",
    "        end_token_position=j\n",
    "        break\n",
    "    tokenized_examples[\"start_positions\"].append(start_token_position)\n",
    "    tokenized_examples[\"end_positions\"].append(end_token_position)\n",
    "\n",
    "  return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2bfbbd-b9fb-4616-8483-dea0f9252ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset=dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d2a9fd-53cf-4a04-9301-1c63f704b9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 19:04:19.188800: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-01 19:04:19.189837: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-01 19:04:19.189911: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-01 19:04:19.192260: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-01 19:04:19.192352: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-01 19:04:19.192412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-01 19:04:19.396962: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-01 19:04:19.397203: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-01 19:04:19.397230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-08-01 19:04:19.397464: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-01 19:04:19.397506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 677 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tokenized_dataset[\"train\"].to_tf_dataset(\n",
    "    shuffle=True, \n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e13129-98be-4983-adc9-498b6cb0db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=tf_dataset.take(int(0.9*len(tf_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb490a6e-d152-4390-b17a-a7fcc9d13d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset=tf_dataset.skip(int(0.9*len(tf_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf4dc1-4832-4ceb-8ca6-350822a8e062",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31e590b8-4f87-42c6-aacb-54ee1f50cc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 19:04:30.238140: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 750.59MiB (rounded to 787046400)requested by op StatelessTruncatedNormalV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-08-01 19:04:30.238219: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-08-01 19:04:30.238244: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 13, Chunks in use: 13. 3.2KiB allocated for chunks. 3.2KiB in use in bin. 109B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238254: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238262: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238269: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238276: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238282: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238289: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238296: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238302: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238309: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238315: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238322: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238329: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238335: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238342: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238348: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238355: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238362: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238368: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238377: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238385: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 0. 677.19MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-08-01 19:04:30.238393: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 750.59MiB was 256.00MiB, Chunk State: \n",
      "2024-08-01 19:04:30.238404: I external/local_tsl/tsl/framework/bfc_allocator.cc:1068]   Size: 677.19MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 256B | Requested Size: 16B | in_use: 1 | bin_num: -1\n",
      "2024-08-01 19:04:30.238410: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 710088704\n",
      "2024-08-01 19:04:30.238418: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600000 of size 256 next 1\n",
      "2024-08-01 19:04:30.238424: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600100 of size 1280 next 2\n",
      "2024-08-01 19:04:30.238430: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600600 of size 256 next 3\n",
      "2024-08-01 19:04:30.238436: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600700 of size 256 next 4\n",
      "2024-08-01 19:04:30.238442: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600800 of size 256 next 5\n",
      "2024-08-01 19:04:30.238448: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600900 of size 256 next 6\n",
      "2024-08-01 19:04:30.238454: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600a00 of size 256 next 7\n",
      "2024-08-01 19:04:30.238460: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600b00 of size 256 next 8\n",
      "2024-08-01 19:04:30.238465: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600c00 of size 256 next 9\n",
      "2024-08-01 19:04:30.238472: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600d00 of size 256 next 10\n",
      "2024-08-01 19:04:30.238478: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600e00 of size 256 next 11\n",
      "2024-08-01 19:04:30.238484: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606600f00 of size 256 next 12\n",
      "2024-08-01 19:04:30.238489: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606601000 of size 256 next 13\n",
      "2024-08-01 19:04:30.238495: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 606601100 of size 256 next 14\n",
      "2024-08-01 19:04:30.238502: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 606601200 of size 710084096 next 18446744073709551615\n",
      "2024-08-01 19:04:30.238508: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-08-01 19:04:30.238515: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 256 totalling 3.2KiB\n",
      "2024-08-01 19:04:30.238526: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-08-01 19:04:30.238538: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 4.5KiB\n",
      "2024-08-01 19:04:30.238551: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 710088704 memory_limit_: 710088704 available bytes: 0 curr_region_allocation_bytes_: 1420177408\n",
      "2024-08-01 19:04:30.238576: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       710088704\n",
      "InUse:                            4608\n",
      "MaxInUse:                         4608\n",
      "NumAllocs:                          15\n",
      "MaxAllocSize:                     1280\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-08-01 19:04:30.238592: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] *___________________________________________________________________________________________________\n",
      "2024-08-01 19:04:30.238626: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at stateless_random_ops_v2.cc:64 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128100,1536] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessTruncatedNormalV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[128100,1536] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessTruncatedNormalV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFAutoModel\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTFAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/deberta-v2-xlarge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:2977\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2975\u001b[0m         model\u001b[38;5;241m.\u001b[39mbuild_in_name_scope()  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2977\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_in_name_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safetensors_from_pt \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sharded:\n\u001b[1;32m   2980\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1197\u001b[0m, in \u001b[0;36mTFPreTrainedModel.build_in_name_scope\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_in_name_scope\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m-> 1197\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py:1393\u001b[0m, in \u001b[0;36mTFDebertaV2Model.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeberta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeberta\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m-> 1393\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeberta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py:1240\u001b[0m, in \u001b[0;36mTFDebertaV2MainLayer.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m-> 1240\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mname):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py:948\u001b[0m, in \u001b[0;36mTFDebertaV2Embeddings.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 948\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitializer_range\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    955\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtype_vocab_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py:712\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layout:\n\u001b[1;32m    710\u001b[0m     getter \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(getter, layout\u001b[38;5;241m=\u001b[39mlayout)\n\u001b[0;32m--> 712\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_variable_with_custom_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# `Trackable` method.\u001b[39;49;00m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgetter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgetter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regularizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# should be variable attributes.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     name_in_scope \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mname[: variable\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:492\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    482\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (checkpoint_initializer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    483\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    484\u001b[0m            (initializer\u001b[38;5;241m.\u001b[39mrestore_uid \u001b[38;5;241m>\u001b[39m checkpoint_initializer\u001b[38;5;241m.\u001b[39mrestore_uid))):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;66;03m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m     initializer \u001b[38;5;241m=\u001b[39m checkpoint_initializer\n\u001b[0;32m--> 492\u001b[0m new_variable \u001b[38;5;241m=\u001b[39m \u001b[43mgetter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_for_getter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# handles slot variables.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137\u001b[0m, in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner, layout, experimental_enable_variable_lifting)\u001b[0m\n\u001b[1;32m    130\u001b[0m     use_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# In theory, in `use_resource` is True and `collections` is empty\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# (that is to say, in TF2), we can use tf.Variable.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# However, this breaks legacy (Estimator) checkpoints because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# it changes variable names. Remove this when V1 is fully deprecated.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dtensor\u001b[38;5;241m.\u001b[39mDVariable(\n\u001b[1;32m    154\u001b[0m         initial_value\u001b[38;5;241m=\u001b[39minit_val,\n\u001b[1;32m    155\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m         shape\u001b[38;5;241m=\u001b[39mvariable_shape \u001b[38;5;28;01mif\u001b[39;00m variable_shape \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    165\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/initializers/initializers.py:524\u001b[0m, in \u001b[0;36mTruncatedNormal.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m     _ensure_keras_seeded()\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mcall_with_layout(\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_generator\u001b[38;5;241m.\u001b[39mtruncated_normal,\n\u001b[1;32m    517\u001b[0m         layout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m         nonce,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[0;32m--> 524\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_random_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruncated_normal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstddev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonce\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend.py:2142\u001b[0m, in \u001b[0;36mRandomGenerator.truncated_normal\u001b[0;34m(self, shape, mean, stddev, dtype, nonce)\u001b[0m\n\u001b[1;32m   2140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2141\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_truncated_normal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstddev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m   2144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mtruncated_normal(\n\u001b[1;32m   2146\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2147\u001b[0m     mean\u001b[38;5;241m=\u001b[39mmean,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2150\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2151\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessTruncatedNormalV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[128100,1536] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessTruncatedNormalV2] name: "
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "model = TFAutoModel.from_pretrained(\"microsoft/deberta-v2-xlarge\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd49345-7d41-40cb-9afd-201028c9e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e072614-17d8-4367-b656-2b0899094c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_dataset,validation_data=val_dataset,epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7890d485-feff-46e3-bda6-44c3d1ffbad5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb56932-7718-42cb-b85d-994426c41e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"How does the virus spread?\"\n",
    "text=\"We know that the disease is caused by the SARS-CoV-2 virus, which spreads between people in several different ways.Current evidence suggests that the virus spreads mainly between people who are in close contact with each other, for example at a conversational distance.The virus can spread from an infected person’s mouth or nose in small liquid particles when they cough, sneeze, speak, sing or breathe. Another person can then contract the virus when infectious particles that pass through the air are inhaled at short range (this is often called short-range aerosol or short-range airborne transmission) or if infectious particles come into direct contact with the eyes, nose, or mouth (droplet transmission). The virus can also spread in poorly ventilated and/or crowded indoor settings, where people tend to spend longer periods of time. This is because aerosols can remain suspended in the air or travel farther than conversational distance (this is often called long-range aerosol or long-range airborne transmission). People may also become infected when touching their eyes, nose or mouth after touching surfaces or objects that have been contaminated by the virus. Further research is ongoing to better understand the spread of the virus and which settings are most risky and why. Research is also under way to study virus variants that are emerging and why some are more transmissible. For updated information on SARS-CoV-2 variants, please read the weekly epidemiologic updates.\"\n",
    "inputs = tokenizer(question, text, return_tensors=\"tf\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])\n",
    "answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])\n",
    "\n",
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "tokenizer.decode(predict_answer_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
